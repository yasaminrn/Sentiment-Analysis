{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This notebook is used for reading data and applying the pre-process on tweet data\n",
    "#The pre-process is the first step to format the data for proper use of Natural language toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing utility libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ENCODING = \"ISO-8859-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#File location and address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#File names are taken automatically from interface company_list\n",
    "#For single use of applying_textprocess, can use the FILE_NAME as shown in exapmle below.\n",
    "#FILE_NAME = 'META.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining column titles\n",
    "#For training/testing data, two columns of text and target are used\n",
    "#For new data, the scraping data has column labels. For current project we are only interested in 'text' column of new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if re.search('train', FILE_NAME) or re.search('test', FILE_NAME):\n",
    "    DATASET_COLUMNS=['text','target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if re.search('train', FILE_NAME) or re.search('test', FILE_NAME):\n",
    "    df = pd.read_csv(FILE_NAME, encoding=DATASET_ENCODING, names=DATASET_COLUMNS)\n",
    "else:\n",
    "    df = pd.read_csv(FILE_NAME, encoding=DATASET_ENCODING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for Null values, in whole table and in text column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "416"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df.isnull().any(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df['text'].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if re.search('train', FILE_NAME):\n",
    "    data=df[['text','target']]\n",
    "elif re.search('test', FILE_NAME):\n",
    "    data=df[['text','target']]\n",
    "else: \n",
    "    data=df[['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mshak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mshak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%run text_process.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing all tweets to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      @Beeftipsy my problem with it being 2 months i...\n",
       "1      To be fair to Meta, this looks much better. ht...\n",
       "2      did netflix recommend \"the watcher\" to me beca...\n",
       "3      $Uber / $Meta; same revenue multiple. One has ...\n",
       "4      RT @BlerdMinusFear: The same folks I see compl...\n",
       "                             ...                        \n",
       "995    $FNGU traded the 2nd highest volume ever in it...\n",
       "996    @BullsPromoter Sup here,specially team leon ou...\n",
       "997    Meta files to dismiss the FTC's attempt to blo...\n",
       "998    @BosoTokyo @Raxworld_io @genso_meta @OldeusOff...\n",
       "999    RT @MMAFighting: UFC partners with Meta for li...\n",
       "Name: text, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As we want to overwrite data frame disbaling the default warning for overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text']=data['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying the cleaning_stopwords function defined in text_process notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text']=data['text'].apply(lambda text: cleaning_stopwords(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying the cleaning_punctuations function defined in text_process notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text']=data['text'].apply(lambda x:cleaning_punctuations(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying the cleaning_repeating_char function defined in text_process notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text']=data['text'].apply(lambda x: cleaning_repeating_char(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying cleaning_URLs function defined in text_process notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text']=data['text'].apply(lambda x: cleaning_URLs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying the cleaning_numbers function defined in text_process notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text']=data['text'].apply(lambda x: cleaning_numbers(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying the word_tokenize function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text']=data['text'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying stemming_on_text function defined in text_process notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text']=data['text'].apply(lambda x: stemming_on_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying lemmatizer_on_text function defined in text_process notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text']=data['text'].apply(lambda x: lemmatizer_on_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [beeftipsy, problem, months, season, still, mo...\n",
       "1      [fair, meta, looks, much, better, httpstcoddvu...\n",
       "2      [netflix, recommend, the, watcher, its, watchi...\n",
       "3      [uber, meta, revenue, multiple, one, ve, margi...\n",
       "4      [rt, blerdminusfear, folks, see, complaining, ...\n",
       "                             ...                        \n",
       "995    [fngu, traded, nd, highest, volume, ever, hist...\n",
       "996    [bullspromoter, sup, herespecially, team, leon...\n",
       "997    [meta, files, dismiss, ftcs, attempt, block, a...\n",
       "998    [bosotokyo, raxworldio, gensometa, oldeusoffic...\n",
       "999    [rt, mmafighting, ufc, partners, meta, live, o...\n",
       "Name: text, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
